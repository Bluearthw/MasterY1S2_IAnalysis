{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yk41Fp6rnQYJ",
    "outputId": "aabeac52-2237-4b76-9211-b05f22851a39"
   },
   "outputs": [],
   "source": [
    "# Uncomment this if you are using Colab\n",
    "# ## Mount google drive: If your dataset is saved on google drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "HPcSwStJm-rS",
    "outputId": "709e96f0-ed8b-4cf0-88f2-a99ba647a5ee"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Step 1: Load the images\n",
    "\n",
    "# b) Load the first image\n",
    "imFirst = np.array(Image.open('./faces/s1/1.pgm'))\n",
    "imFirst = imFirst.astype('float32')\n",
    "imFirst /= 255.0\n",
    "imFirst = np.clip(imFirst, 0.0, 1.0)\n",
    "plt.imshow(imFirst, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# c) Load the training images (40 persons X 7 images)\n",
    "nTrainImages = 40 * 7  # number of training images\n",
    "height, width = imFirst.shape  # The images have the same size. Use the first one to calculate the number of pixels\n",
    "imagesTrain = np.zeros((height * width, nTrainImages))  # Matrix with the training images as rows\n",
    "for i in range(1, 41):\n",
    "    for j in range(1, 8):\n",
    "        filename = f'./faces/s{i}/{j}.pgm'\n",
    "        img = np.array(Image.open(filename))\n",
    "        img = img.astype('float32')\n",
    "        img /= 255.0\n",
    "        img = np.clip(img, 0.0, 1.0)\n",
    "        imagesTrain[:, (i-1)*7 + (j-1)] = img.flatten()\n",
    "\n",
    "# d) read testing images.\n",
    "nTestImages = 40 * 3  # testing images\n",
    "imagesTest = np.zeros((height * width, nTestImages))\n",
    "for i in range(1, 41):\n",
    "    for j in range(8, 11):\n",
    "        filename = f'./faces/s{i}/{j}.pgm'\n",
    "        img = np.array(Image.open(filename))\n",
    "        img = img.astype('float32')\n",
    "        img /= 255.0\n",
    "        img = np.clip(img, 0.0, 1.0)\n",
    "        imagesTest[:, (i-1)*3 + (j-8)] = img.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference: Explaination of why use $A^T A$ for eigenvalue (answered by GPT4)\n",
    "\n",
    "The relation between $A^T A$ and the covariance matrix of $A$, where $A$ is a matrix whose columns are random variables that follow a zero-mean distribution, is quite direct.\n",
    "\n",
    "The covariance matrix $ \\Sigma $ of $ A $ is defined as $ \\Sigma = E[(A - \\mu)(A - \\mu)^T] $, where $ \\mu $ is the mean vector of the columns of $ A $. Since in your case each column of $ A $ follows a zero-mean distribution, $ \\mu = 0 $. Therefore, the covariance matrix simplifies to $ \\Sigma = E[AA^T] $.\n",
    "\n",
    "However, $ A^T A $ is a related but slightly different quantity. It is not the covariance matrix of the columns of $ A $, but rather a matrix that represents the dot products between all pairs of columns in $ A $. In the context of zero-mean data, $ A^T A $ can be seen as a scaled version of the covariance matrix when the data is centered but not necessarily scaled to unit variance. Specifically, if $ A $ is a data matrix with zero-mean columns, then $ A^T A $ divided by $ n-1 $, where $ n $ is the number of observations (rows in $ A $), gives the sample covariance matrix of the data in $ A $.\n",
    "\n",
    "So, in summary, for zero-mean data:\n",
    "- The covariance matrix $ \\Sigma $ of $ A $ is $ E[AA^T] $.\n",
    "- $ A^T A $ represents the sum of squares and cross-products matrix for the columns of $ A $.\n",
    "- $ \\frac{1}{n-1} A^T A $ gives the sample covariance matrix of $ A $ when $ A $ has zero-mean columns.\n",
    "\n",
    "**But:** if you really encounter OOM issue for large dataset PCA, please refer to incremental PCA or other way to estimate the components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "KCMnU8ajozO2",
    "outputId": "05793405-cb1b-4f7a-bdbb-e23fecb19af8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 2: PCA\n",
    "# a) find the mean image\n",
    "mean_face = np.mean(imagesTrain, axis=1)\n",
    "\n",
    "image_height, image_width = height, width\n",
    "# TODO: visualize mean_face\n",
    "plt.imshow(mean_face.reshape(image_height, image_width), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# b) mean-shifted input images\n",
    "shifted_images = imagesTrain - mean_face[:, np.newaxis]\n",
    "\n",
    "# This is a pre-step to optimize calculation. (see your lecture notes)\n",
    "# TODO: normally we should find the covariance of shifted_images but it will be a 10304*10304 matrix!\n",
    "# to be optimized and avoid \"out of memory\" error, we use a trick! (see chapter 6 of the book (p. 164)\n",
    "# Compute Y'*Y \n",
    "YY = 1/shifted_images.shape[0] * np.dot(shifted_images.T, shifted_images)\n",
    "\n",
    "# c) Compute eigenvectors\n",
    "evalues, evectors = np.linalg.eig(YY)\n",
    "evectors = np.dot(shifted_images, evectors)\n",
    "\n",
    "# d) Sort eigenvectors based on their corresponding eigenvalues\n",
    "# TODO: put the results in \"evectors\" variable\n",
    "sorted_indices = np.argsort(evalues)[::-1]\n",
    "evectors = evectors[:, sorted_indices]\n",
    "evalues = evalues[sorted_indices]\n",
    "\n",
    "# e) only retain the top 'num_eigenfaces' eigenvectors (i.e. the principal components)\n",
    "num_eigenfaces = 30\n",
    "evectors = evectors[:, :num_eigenfaces]\n",
    "\n",
    "# Normalize the eigenvectors so || evector_i|| = 1\n",
    "for i in range(num_eigenfaces):\n",
    "    evectors[:, i] /= np.linalg.norm(evectors[:, i])\n",
    "\n",
    "# f) project the images into the subspace to generate the feature vectors\n",
    "# TODO: put the results in \"features\" variable\n",
    "features = np.dot(shifted_images.T, evectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "m7QgxnmAdBy-",
    "outputId": "793323ff-655d-4d9b-a2a6-270e23f37461"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 3: Analysis of eigen faces\n",
    "# a) display the eigenvectors\n",
    "fig, axes = plt.subplots(1, num_eigenfaces, figsize=(12, 4))\n",
    "for n in range(num_eigenfaces):\n",
    "    evector = evectors[:, n].reshape(height, width)\n",
    "    axes[n].imshow(evector, cmap='gray')\n",
    "    axes[n].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) display the cumulative eigenvalues\n",
    "cumulative_sum = np.cumsum(evalues)\n",
    "plt.plot(cumulative_sum / np.sum(evalues))\n",
    "plt.xlabel('Number of eigenfaces')\n",
    "plt.ylabel('Cumulative sum of eigenvalues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "VdMlkn6RaH-P",
    "outputId": "9f5fecd1-b985-4324-94d9-e984c3f9fd16"
   },
   "outputs": [],
   "source": [
    "# Step 4: Identify a person\n",
    "testIm = 100 # chose a person index\n",
    "input_image = np.expand_dims(imagesTest[:, testIm],-1)\n",
    "# Tips: a shortcut way in python is input_image = imagesTest[:, testIm][..., None]\n",
    "\n",
    "shifted_input_image = input_image - mean_face[:, np.newaxis]\n",
    "shifted_imagesTrain = imagesTrain - mean_face[:, np.newaxis]\n",
    "\n",
    "# calculate the similarity of the input to each training image\n",
    "# feature_vec = np.dot(input_image.T, evectors)\n",
    "input_image_feature =  np.dot(shifted_input_image.T, evectors)\n",
    "imagesTrain_feature =  np.dot(shifted_imagesTrain.T, evectors)\n",
    "\n",
    "similarity_score = np.zeros((len(imagesTrain_feature)))\n",
    "for i in range(0,len(imagesTrain_feature)):\n",
    "    similarity_score[i] = 1/(1+np.linalg.norm(input_image_feature-imagesTrain_feature[i])) # norm can be regarded as distance between two vectors\n",
    "\n",
    "# find the image with the highest similarity\n",
    "match_ix = np.argmax(similarity_score)\n",
    "\n",
    "# display the result\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(input_image.reshape(height, width), cmap='gray')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(imagesTrain[:, match_ix].reshape(height, width), cmap='gray')\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title(f\"matches to the {match_ix}th training sample with score {similarity_score[match_ix]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "iNqJ-JYa4sCM",
    "outputId": "52456e3e-aad4-4e50-f78b-4824cba48e05"
   },
   "outputs": [],
   "source": [
    "# Step 5: Cluster the persons\n",
    "\n",
    "# a) Cluster the original images\n",
    "# put the results in \"clusters\" variable. \"clusters\" indicates cluster number for each sample.\n",
    "# hint: use kmeans function\n",
    "from sklearn.cluster import KMeans\n",
    "NUM_PERSONS = 40\n",
    "kmeans = KMeans(n_clusters=NUM_PERSONS)\n",
    "kmeans.fit(imagesTrain.T)\n",
    "clusters = kmeans.labels_\n",
    "\n",
    "# Show the the images that were assigned to cluster 1\n",
    "img_index = np.where(clusters == 0)[0]\n",
    "\n",
    "for i in range(min(len(img_index), 7)):\n",
    "    plt.figure(111)\n",
    "    plt.subplot(1, 7, i+1)\n",
    "    img = np.reshape(imagesTrain[:, img_index[i]], (height, width))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Now cluster on the reduced space\n",
    "# put the results in \"clusters_pca\" variable.\n",
    "kmeans_pca = KMeans(n_clusters=NUM_PERSONS)\n",
    "kmeans_pca.fit(features)\n",
    "clusters_pca = kmeans_pca.labels_\n",
    "\n",
    "# Show the the images that were assigned to cluster 1\n",
    "img_index = np.where(clusters_pca == 0)[0]\n",
    "for i in range(min(len(img_index), 7)):\n",
    "    plt.figure(111)\n",
    "    plt.subplot(1, 7, i+1)\n",
    "    img = np.reshape(imagesTrain[:, img_index[i]], (height, width))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) Try agglomerative clustering on some images\n",
    "# hint: use linkage command for agglomerative clustering with \"single\" metric and put the results in \"Z_agglo\" variable\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "\n",
    "checkImages = list(range(8,21))\n",
    "\n",
    "Z_agglo = linkage(imagesTrain.T[checkImages], method='single')\n",
    "\n",
    "fig = plt.figure()\n",
    "dn = dendrogram(Z_agglo)\n",
    "c = fcluster(Z_agglo, t=2, criterion='maxclust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the the images that were assigned to cluster 1\n",
    "img_index = np.where(c == 1)[0]\n",
    "for i in range(min(len(img_index), 5)):\n",
    "    plt.figure(111)\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    img = np.reshape(imagesTrain[:, checkImages[img_index[i]]], (height, width))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA\n",
    "\n",
    "1. how to implement python-style image batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = []\n",
    "for i in range(5):\n",
    "    a = np.zeros((10,20,3)) # for instance a is the loaded image\n",
    "    print(f\"image size at stage {i} is {a.shape}\")\n",
    "    arr.append(a)\n",
    "arr_np = np.stack(arr)\n",
    "print(\"batched arr size\", arr_np.shape)\n",
    "print(\"flatten images in the batch\", arr_np.reshape(arr_np.shape[0], -1).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
